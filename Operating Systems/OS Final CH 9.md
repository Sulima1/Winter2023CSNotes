#CP386 

## 9.1 
- CPU fetches memory according to the value of the program counter
- A typical instruction cycle is:
	- First fetch the instruction from memory
	- Then, decode the instruction 
	- Execute the instruction and store the results back in memory

### Basic Hardware
- When a process requires memory and the processor does not yet have the memory required, it needs to **stall** the process
	- The remedy is to add fast memory between the CPU and main memory
	- This is called a **cache** and it is built into the CPU

- In order to make sure each process has a seperate memory space, we need to supply two registers:
	- The **base register** holds the smallest legal physical memory addresses
	- The **limit register** specifies the size of the range
- For example if the base register holds `300040` and the limit register is `120900`, then the program can access all memory from `300040` to `420939` (inclusive)
	- upperbound = base register + limit register - 1

- Any attempt by a program executing in user mode o access operating system memory (or other users memory) results in a trap to the operating system
	- Prevents the user from deliberately modfying the code or data structures of the OS
- The OS executing in kernel mode is given unrestricted access to the operating system and user's memory


### Address Binding
- A user program goes through many steps before being executed, memory addresses may be represented in different ways during these steps
- Addresses in the source program are generally symbolic
- A compiler **binds** these symbolic addresses to relocatable addresses
- The linker or loader binds the relocatable addresses to absolute addresses

- Typically, binding instructions can be done at any step along the way
	- **Compile time**: If you know at compile that where the process will reside in memory, then **absolute code** can be generated. 
		- Absolute code refers to code where all memory addresses are resolved before the program is executed
	- **Load time**: If it is not known where the process will reside in memory at compile time then, then the compiler must generate **relocatable code**
	- **Execution time**: If the process can be moved during its execution from one segment to another, the binding must be delayed until run time


### Logical Versus Physical Address Space
- An address generated by the CPU is commonly referred to as a **logical address**
- The addresses loaded in to the **memory address register** are referred to as **physical addresses**
![[Pasted image 20230418165737.png | 400]]

- Binding addresses generate identical logical and physical addresses
	- We can refer to the logical address as a **virtual address**

- The set of all logical addresses generated by a program is called the **logical address space**
- The set of all physical addresses generated by a program is called the **physical address space**
- In execution time, the logical and physical address spaces differ

- The mapping of virtual to physical addresses is done by a hardware device called the **memory-management unit (MMU)**
- The base register is now called the **relocation register**
- The value of the relocation register is added to every address generated by a user process at the time the address is sent to memory

- If the base is at `14000` , then an attempt by the user address location `0` is dynamically relocated to location `14000`
- An access to location `346` is mapped to location `14346`

- Logical addresses go from range 0 to *max*
- Physical addresses go from *R* + 0 to *R* + *max* where *R* is the base register value
- Think of the base register value as the **seperator** between logical address and physical address

### Dynamic Loading
- **Dynamic loading** is a process that obtains better memory-space utilization
- In **dynamic loading** a routine is not loaded until it is called


### Dynamic Linking and Shared Libraries
- **Dynamically linked libraries (DLLs)** are system libraries that are linked to user programs when the programs are run
- Some operating systems only support **static linking** where system libraries are treated like any other object module
- **Dynamic linking** is similar to **dynamic loading** but rather linking is postponed until execution time

- Since DLLs are shared among multiple processes, they are also known as **shared libraries**


## 9.2
- **Contiguous memory allocation** is a memory allocation technique where memory is divided into partitions and allocated to a process when it is requested
- The memory is usually divided into two partitions: one for the OS and one for the use process

### Memory Protection
-  Processes are prohibiting from accessing memory is doesnt own through a **relocation register** and a **limit register**
- The **relocation register** holds the smallest physical memory address and the **limit register** holds the range of logical addresses
- The CPU generates and address which is then checked against the relocation and limit registers to fall within the range

### Memory Allocation
- One of the simplest methods is to assign processes to variably sized partitions in memory, where each partition may contain exactly one process
	- This is called the **variable partition scheme**
- In the **variable partition scheme** the OS keeps a table indicating which parts of the memory are available and which are occupied
- A large block of empty memory is called a **hole**

- When a process arrives and needs memory, the opearting system searches for a hole that is large enough for the process
	- If the hole is too large, it is split into two parts

- Dynamically giving memory of different sizes to a process is called the **dynamic storage allocation problem**
	- There are many solutions to this problem **first-fit**, **best-fit**, and **worst-fit** strategies

- **First-fit**: Allocate the first hole that is big enough. Searching can start either at the beginning of the set of holes or the location where the previous first search ended. Stop searching as soon as a hole is found
- **Best-fit**: Allocate the smallest hole that is big enough. We must search the entire list, unless the list is ordered by size
- **Worst-fit**: Allocate the largest hole. Search through the entire list, unless sorted by size. 


### Fragmentation
- Both first-fit and best-fit strategies suffer from **external fragmentation**
- As processes are loaded and removed from memory, the free memory space is broken into little pieces
- External fragmentation exists when there is enough total memory space to satisfy a request but the available space is not contiguous

#### ELI5
- Basically, processes are not stored adjacently and it leads to seperating holes and creating smaller sections
- It can lead to later processes not having holes large enough to support them

- The **50-percent rule** states that allocation of memory blocks with first-fit and best-fit strategies leads to 1/3 of unused memory from fragmentation

- One solution to **external fragmentation** is to break up the holes into pre-determined sizes
	- Downside is that it leads to **internal fragmentation** where processes are given blocks that are too large leading to unused memory inside of processes

- Another solution to external fragmentation is **compaction**
- Shuffle all the memory contents to place all the free memory together in one large block
	- Compaction is not always possible: if relocation is static nd done at assembly or load time then compaction is impossible


## 9.3
- **Paging** is a memory management scheme that permits a process's physical address space to be non-contiguous

### Basic Method
- The basic paging method involves breaking logical memory into groups called **frames** and physical memory into groups called **pages**

- Every address generated by the CPU is divided into two parts: a **page number (p)** and a **page offset (d)**
- The **page number** is used as an index into a process table called a **page table**
	- The **page table** contains the base address of each frame in physical memory and the offset is the location in the frame being referenced
- The base address of a frame is combined with the page offset to define the physical memory address

- These are the steps taken by the MMU to translate a logical address generated by the CPU into a physical address
	1. Extract the page number *p* and use it to as an index into the page table
	2. Extract the corresponding frame number *f* from the page table
	3. Replace the page number *p* in the logical address with the frame number *f*
- Since the offset *d* does not change, it is not replaced, and the frame number and offset now comprise the physical address

- Linux supports two page sizes: a normal page that is around 4KB and a larger page size called **huge pages**
	- page size information can be retrieved by calling `getpagesize()`

- Physical memory is stored via frames into a **frame table**


### Hardware Support
- Modern computers store the page table in main memory and use a **page-table base register** to point to the location of the page table
- A faster but less feasible option is to store it in a set of registers

#### Translation Look-Aside Buffer
- Memory access is slowed by using a page-table base register to point to the page table
- The solution is to use a small, fast-lookup hardware cache called a **translation look-aside buffer (TLB)**
- The TLB is high speed memory
- Each entry in the TLB consists of 2 parts: a key (or tag) and a value
	- When the memory is presented with an item, the item is compared with all keys simultaneously
	- if the item is found, the field value is returned
- Basically a reall low level hash table with keys and values tat maps virtual addresses to physical addresses

- If something is not found in the TLB, it is known as a **TLB miss**

- Some TLBs allow for some entires to be **wired down** meaning that they cannot be removed from the TLB

- Some TLBs store **address-space identifier (ASIDs)** in each TLB entry
- An ASID uniquely identifies each process and provides address space protection

- When the TLB is erased or cleared it is being **flushed**

- The percentage of times a page number is found in a TLB is called the **hit ratio**


### Protection
- In order to protect memory, bits can be added to pages 
- A common pracice is to add **valid-invalid** bits
- When the bit is *valid* the page is in the processes logical address space and is legal
- When it is *invalid* the page is not in the processes logical address space and is illegal

- To avoid having valid pages that are outside the limit register, some operating systems have **page-table length register (PTLR)** that indice the size of the page table


### Shared Pages
- If code is **reentrant code** it can be shared
	- **reentrant code** is code that can be safely exeucted by multiple threads or processes at the same time

## 9.4

### Hierarchical Paging
- If a page size in a system is 4KB ($2^{12}$) then a page table must consist of over 1 million entries ($2^{20} = 2^{32} / 2^{12}$)
- A **forward mapped page table** only stores the start of the page (instead of the whole range compared to normal page tables) and the address of the physical memory frame instead of the physical memory frame itself
	- faster search because it has the frame address but larger page table size because it holds an entry for every possible address

### Hashed Page Tables
- A **hashed page table** is a table where the page number is stored as a hash value
- The hashed table stores a linked list of elements for each entry that hold:
	- the virtual page number
	- the value of the mapped page frame
	- a pointer to the next element in the linked list

- Another alternative is **clustered page tables** where each entry in the table stores several pages instead of just one
	- Solves the problem of **sparse** page tables


### Inverted Page Tables
- An **inverted page table** is a page table that stores physical addresses and maps them to virtual addresses (hence, inverted)
- The advantage is that it reduces the size of the page table and allows processes to share physical memory more efficiently


## 9.5
- Processes can be temporarily **swapped** out of memory to a **backing store** and then brought back later to be executed
	- Swapping lets the system exceed the real physical memory and increase the degree of multiprogramming

- Standard swapping involves moving entire processes between main memory and a backing store


### Swapping with Paging
- A **page out** operation moves a page from memory to the backing store
	- The reverse process is known as **page in**

### Swapping on Mobile Systems
- Most operating systems for PCs and servers support swapping pages
- Most mobile systems do not support swapping due to hardware size constraints

- Many mobile devices today voluntarily ask the application to relinquish memory 
- They then save the **application state** so that it can quickly be restarted once it is called again


## 9.7
- The ARMv8 operating system has three different **translation granules**: 4KB, 16KB, and 64KB
- Each granule provides different pages sizes and large sections of contiguous memory which are known as **regions**

- ARMv8 has a **translation table base register** that points to the level 0 for the current thread

- The ARM architecutre also supports 2 levels of TLBs:
	- **micro TLBs**: which are a TLB for data and instructions (also supports ASIDs)
	- **main TLB**